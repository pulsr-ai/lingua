# Database - provide either DATABASE_URL or individual components
DATABASE_URL=postgresql://postgres:password@localhost:5432/llm_wrapper

# OR use individual components (uncomment these and comment out DATABASE_URL above)
# DB_HOST=localhost
# DB_PORT=5432
# DB_USER=postgres
# DB_PASSWORD=password
# DB_NAME=llm_wrapper

# Redis (for async operations)
REDIS_URL=redis://localhost:6379

# LLM Providers
OPENAI_API_KEY=your-openai-api-key
OPENAI_API_BASE_URL=
ANTHROPIC_API_KEY=your-anthropic-api-key
DEFAULT_MODEL=

# Local LLM endpoint (e.g., for Ollama or similar)
LOCAL_LLM_ENDPOINT=http://localhost:11434

# Private cloud endpoint
PRIVATE_CLOUD_ENDPOINT=https://your-private-llm.com
PRIVATE_CLOUD_API_KEY=your-private-api-key

# Default provider (openai, anthropic, local, private)
DEFAULT_LLM_PROVIDER=openai

# Server settings
HOST=0.0.0.0
PORT=8000
RELOAD=true

# Telemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=llm-wrapper-service